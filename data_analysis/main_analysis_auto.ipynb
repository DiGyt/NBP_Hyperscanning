{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Analysis\n",
    "\n",
    "This file does not rely on user input. So we would like to keep it interchangeable with the actual main_analysis.py file.\n",
    "So please keep all the >relevant< code within one code block. (If you want to inspect certain elements or do other things that are not relevant to the main analysis, you can of course add them in new blocks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/net/store/nbp/projects/hyperscanning/study_project/programming_tools/miniconda3/envs/hyperscanning/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /net/store/nbp/projects/hyperscanning/hyperscanning-2.0/mne_data/sourcedata/sub-202/eeg/sub-202_task-hyper_eeg.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-da680b7874bf>:40: RuntimeWarning: This filename (/net/store/nbp/projects/hyperscanning/hyperscanning-2.0/mne_data/sourcedata/sub-202/eeg/sub-202_task-hyper_eeg.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz or _meg.fif\n",
      "  combined_raw = mne.io.read_raw_fif(subs_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isotrak not found\n",
      "    Range : 0 ... 3725311 =      0.000 ...  3637.999 secs\n",
      "Ready.\n",
      "Opening raw data file /net/store/nbp/projects/hyperscanning/hyperscanning-2.0/mne_data/sourcedata/sub-202/eeg/sub-202_task-hyper_eeg-1.fif...\n",
      "Isotrak not found\n",
      "    Range : 3725312 ... 5675445 =   3638.000 ...  5542.427 secs\n",
      "Ready.\n",
      "Reading 0 ... 5675445  =      0.000 ...  5542.427 secs...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying a custom EEG reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying a custom EEG reference.\n",
      "6648 events found\n",
      "Event IDs: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 36 37 38 39 40 41 42 43 44 45 46 48 49]\n",
      "6648 events found\n",
      "Event IDs: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 36 37 38 39 40 41 42 43 44 45 46 48 49]\n",
      "900 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 900 events and 1537 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-da680b7874bf>:84: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw_combined, combined_events, tmin=tmin, tmax=tmax,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f77d4e958624d839549a848762fe58c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Repairing epochs', layout=Layout(flex='2'), max=900.0, st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dropped 418 epochs: 0, 1, 2, 3, 4, 5, 8, 9, 10, 12, 16, 17, 22, 23, 24, 28, 30, 31, 35, 36, 39, 40, 41, 47, 49, 52, 53, 59, 60, 61, 64, 65, 66, 67, 70, 71, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 99, 100, 102, 114, 116, 120, 121, 123, 132, 133, 135, 138, 140, 144, 145, 146, 147, 152, 155, 158, 160, 166, 167, 168, 170, 173, 174, 175, 176, 178, 179, 180, 181, 182, 184, 185, 186, 188, 190, 191, 192, 193, 197, 199, 203, 206, 208, 210, 211, 212, 213, 215, 217, 218, 219, 220, 222, 223, 224, 225, 227, 229, 231, 232, 235, 237, 238, 240, 242, 246, 250, 251, 252, 254, 255, 256, 257, 258, 259, 260, 265, 267, 270, 275, 277, 279, 282, 283, 284, 285, 286, 288, 290, 291, 293, 295, 297, 299, 312, 313, 316, 318, 322, 324, 325, 330, 331, 336, 338, 341, 345, 347, 354, 356, 358, 360, 361, 362, 364, 373, 381, 383, 386, 389, 390, 391, 392, 393, 394, 395, 398, 403, 404, 407, 409, 413, 425, 430, 434, 435, 440, 442, 443, 444, 446, 457, 461, 464, 467, 470, 471, 474, 478, 485, 486, 487, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 504, 506, 508, 509, 510, 513, 517, 518, 519, 522, 524, 527, 528, 530, 531, 537, 539, 543, 547, 548, 549, 550, 551, 552, 553, 554, 557, 558, 559, 563, 565, 567, 570, 571, 572, 573, 576, 579, 581, 582, 588, 590, 592, 594, 595, 596, 598, 599, 601, 603, 604, 605, 606, 607, 609, 612, 613, 615, 620, 621, 624, 625, 629, 630, 632, 635, 637, 642, 644, 645, 647, 648, 649, 652, 653, 655, 659, 660, 662, 665, 666, 667, 669, 672, 673, 681, 683, 686, 687, 688, 689, 692, 693, 694, 695, 696, 698, 699, 702, 703, 706, 708, 718, 722, 725, 731, 732, 734, 736, 737, 738, 739, 742, 744, 746, 747, 749, 755, 756, 760, 761, 762, 765, 767, 768, 774, 775, 777, 778, 780, 782, 783, 785, 786, 787, 788, 790, 791, 793, 796, 798, 802, 803, 804, 805, 806, 808, 812, 813, 815, 816, 817, 819, 821, 824, 826, 827, 828, 829, 830, 836, 837, 839, 840, 841, 842, 844, 845, 846, 848, 849, 850, 852, 854, 855, 856, 857, 859, 860, 861, 863, 864, 865, 866, 873, 876, 883, 884, 887, 888, 891, 892, 894, 896, 897, 898, 899\n",
      "Reading /net/store/nbp/projects/hyperscanning/study_project/dirk/NBP_Hyperscanning/data_analysis/bads/bad_components/sub-202_p-0-ica.fif ...\n",
      "Now restoring ICA solution ...\n",
      "Ready.\n",
      "Transforming to ICA space (63 components)\n",
      "Zeroing out 1 ICA component\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom EEG reference.\n",
      "Fitted sphere radius:         95.1 mm\n",
      "Origin head coordinates:      0.9 6.5 47.0 mm\n",
      "Origin device coordinates:    0.9 6.5 47.0 mm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb8f6b9bd67453fafc78b8d32f46d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Repairing epochs', layout=Layout(flex='2'), max=900.0, st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dropped 46 epochs: 2, 23, 44, 48, 50, 52, 53, 55, 67, 68, 79, 83, 90, 107, 126, 145, 146, 157, 164, 174, 181, 185, 195, 197, 199, 211, 226, 239, 242, 254, 256, 273, 274, 275, 276, 277, 284, 293, 320, 524, 582, 673, 682, 702, 738, 765\n",
      "Reading /net/store/nbp/projects/hyperscanning/study_project/dirk/NBP_Hyperscanning/data_analysis/bads/bad_components/sub-202_p-1-ica.fif ...\n",
      "Now restoring ICA solution ...\n",
      "Ready.\n",
      "Transforming to ICA space (63 components)\n",
      "Zeroing out 2 ICA components\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom EEG reference.\n",
      "Fitted sphere radius:         95.1 mm\n",
      "Origin head coordinates:      0.9 6.5 47.0 mm\n",
      "Origin device coordinates:    0.9 6.5 47.0 mm\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "All data dimensions except channels must match, got [ 482 1537] != [ 854 1537]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-da680b7874bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m#combine the epochs again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mepochs_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/store/nbp/projects/hyperscanning/study_project/dirk/NBP_Hyperscanning/data_analysis/functions_preprocessing.py\u001b[0m in \u001b[0;36mcombine_epochs\u001b[0;34m(epochs_1, epochs_2)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;31m# merge the eeg data, info and annotations into one file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mepochs_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_channels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepochs_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mepochs_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/store/nbp/projects/hyperscanning/study_project/programming_tools/miniconda3/envs/hyperscanning/lib/python3.8/site-packages/mne/channels/channels.py\u001b[0m in \u001b[0;36madd_channels\u001b[0;34m(self, add_list, force_update_info)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m                 raise AssertionError('All data dimensions except channels '\n\u001b[0m\u001b[1;32m    926\u001b[0m                                      \u001b[0;34m'must match, got %s != %s'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m                                      % (shapes[0], shape))\n",
      "\u001b[0;31mAssertionError\u001b[0m: All data dimensions except channels must match, got [ 482 1537] != [ 854 1537]"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os.path as op\n",
    "module_path = op.abspath(op.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "\n",
    "from data_analysis.functions_preprocessing import \\\n",
    "    (combine_raws, split_raws, combine_epochs, split_epochs,\n",
    "     preprocess_single_sub, load_ica, load_autoreject)\n",
    "from data_analysis.functions_behavioral import \\\n",
    "    (create_event_df, remove_ghost_triggers, calculate_alpha,\n",
    "     join_event_dfs, remove_outliers, events_from_event_df)\n",
    "from data_analysis.functions_connectivity import \\\n",
    "    epochs_ispc\n",
    "from data_analysis.functions_graph_theory import \\\n",
    "    epochs_weighted_small_world_coeff\n",
    "\n",
    "\n",
    "\n",
    "subject_dir = \"/net/store/nbp/projects/hyperscanning/hyperscanning-2.0/mne_data/sourcedata/\"\n",
    "behav_dir = \"/net/store/nbp/projects/hyperscanning/study_project/NBP_Hyperscanning/data_analysis/Behavioural_Analysis/BehaviouralData\"\n",
    "\n",
    "\n",
    "\n",
    "# Main Data Analysis ###################################\n",
    "# initialize containers to analyze later\n",
    "connectivity_matrices = []\n",
    "small_world_coeffs = []\n",
    "\n",
    "# Perform the data analysis\n",
    "for subj_pair in ['202']:  #['202','203','204','205','206','207','208','209','211','212']:\n",
    "\n",
    "    subs_path = subject_dir + \"sub-{0}/eeg/sub-{0}_task-hyper_eeg.fif\".format(subj_pair)\n",
    "    behav_path = op.join(behav_dir, \"{0}.csv\".format(subj_pair))\n",
    "\n",
    "    combined_raw = mne.io.read_raw_fif(subs_path, preload=True)\n",
    "\n",
    "    # split the subjects and delete the raw file\n",
    "    raws = split_raws(combined_raw)\n",
    "    del combined_raw\n",
    "    \n",
    "    for i, _ in enumerate(raws):\n",
    "        # set the EEG Montage. We use 64 chans from the standard 10-05 system.\n",
    "        montage = mne.channels.make_standard_montage(\"standard_1005\")\n",
    "        raws[i].set_montage(montage)\n",
    "\n",
    "    # combine the subjects again\n",
    "    raw_combined = combine_raws(raws[0], raws[1])\n",
    "    del raws  # to save memory\n",
    "\n",
    "    # do the behavioral analysis and get the epochs\n",
    "    behavioral_df = calculate_alpha(pd.read_csv(behav_path))\n",
    "    event_df = create_event_df(raw_combined)\n",
    "    event_df = remove_ghost_triggers(event_df)\n",
    "    event_df = join_event_dfs(event_df, behavioral_df)\n",
    "    \n",
    "    # get the first tap by looking at the first sample in each trial\n",
    "    min_idx = event_df.groupby([\"trial\"])[\"sample\"].idxmin()\n",
    "    early_df = event_df[event_df.index.isin(min_idx)]\n",
    "    early_events = events_from_event_df(early_df)\n",
    "    \n",
    "    # get the late taps by looking at the last sample - 1.5 seconds\n",
    "    max_idx = event_df.groupby([\"trial\"])[\"sample\"].idxmax()\n",
    "    late_df = event_df[event_df.index.isin(max_idx)]\n",
    "    late_events = events_from_event_df(late_df)\n",
    "    late_events[:,0] -= int(raw_combined.info[\"sfreq\"] * 1.5)\n",
    "    \n",
    "    # get the baseline events\n",
    "    base_events = mne.pick_events(mne.find_events(raw_combined, shortest_event=1),\n",
    "                              include=48)\n",
    "\n",
    "    # define the parameters for epoching\n",
    "    # TODO: Define events more elaborate!\n",
    "    combined_events = np.vstack([base_events, early_events, late_events])\n",
    "    tmin = 0\n",
    "    tmax = 1.5\n",
    "\n",
    "    # epoch the data. Here we filter out bad segments from both participants\n",
    "    # TODO: do we need a baseline for the connectivity analysis?\n",
    "    epochs = mne.Epochs(raw_combined, combined_events, tmin=tmin, tmax=tmax,\n",
    "                        picks=[\"eeg\"], baseline=None, preload=True) # only use the first two epochs\n",
    "    \n",
    "    # split the epochs to apply AR & ICA individually\n",
    "    epochs_split = list(split_epochs(epochs))\n",
    "    for i, cur_eps in enumerate(epochs_split):\n",
    "        subj_id = \"sub-{0}_p-{1}\".format(subj_pair, i)\n",
    "\n",
    "        # apply autoreject (exclude bads and interpolate)\n",
    "        # TODO: The Autoreject guys apply ICA first and then autoreject local. i would do the same\n",
    "        ar = load_autoreject(subj_id)\n",
    "        cur_eps = ar.transform(cur_eps, return_log=False)\n",
    "\n",
    "        # apply ICA\n",
    "        ica = load_ica(subj_id)\n",
    "        cur_eps = ica.apply(cur_eps)\n",
    "        \n",
    "        # rereference to avg ref\n",
    "        cur_eps.set_eeg_reference(ref_channels='average')\n",
    "\n",
    "        # APPLY LAPLACIAN\n",
    "        cur_eps = mne.preprocessing.compute_current_source_density(cur_eps,\n",
    "                                                                   stiffness=10,\n",
    "                                                                   lambda2=1e-5)\n",
    "        epochs_split[i] = cur_eps\n",
    "\n",
    "    #combine the epochs again\n",
    "    epochs = combine_epochs(epochs_split[0], epochs_split[1])\n",
    "    del epochs_split\n",
    "    \n",
    "    # frequencies should be 25 freqs, log spaced between 4 and 50\n",
    "    np.logspace(np.log10(4), np.log10(50), 25)\n",
    "    cycles = freqs / 2.\n",
    "    \n",
    "    # calculate the ISPC\n",
    "    ispc_matrix, freqs, times = epochs_ispc(epochs, freqs, cycles, n_jobs=4)\n",
    "    \n",
    "    print(\"ISPC DONE\")\n",
    "    \n",
    "    # calculate the small world coefficient\n",
    "    small_worlds = epochs_weighted_small_world_coeff(ispc_matrix)\n",
    "    \n",
    "    # append the results to the respective lists\n",
    "    connectivity_matrices.append(ispc_matrix)\n",
    "    small_world_coeffs.append(small_worlds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /net/store/nbp/projects/hyperscanning/study_project/dirk/NBP_Hyperscanning/data_analysis/bads/bad_components/sub-202_p-0-ica.fif ...\n",
      "Now restoring ICA solution ...\n",
      "Ready.\n",
      "Transforming to ICA space (63 components)\n",
      "Zeroing out 1 ICA component\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06edb10ff68849bc9f22d1de9de5b6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Repairing epochs', layout=Layout(flex='2'), max=900.0, st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dropped 378 epochs: 0, 1, 3, 4, 5, 8, 9, 10, 12, 16, 19, 22, 23, 24, 28, 30, 31, 35, 36, 40, 41, 47, 49, 52, 53, 59, 60, 61, 64, 65, 66, 67, 70, 71, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 97, 99, 100, 102, 114, 116, 120, 121, 122, 129, 132, 133, 135, 138, 140, 144, 145, 146, 147, 152, 154, 155, 158, 160, 166, 167, 168, 170, 174, 175, 176, 178, 179, 180, 181, 182, 184, 185, 186, 188, 190, 191, 192, 193, 197, 199, 202, 203, 206, 208, 210, 211, 212, 213, 215, 217, 218, 219, 220, 222, 223, 224, 225, 227, 229, 231, 232, 235, 237, 238, 240, 242, 246, 250, 251, 252, 254, 255, 256, 258, 259, 260, 265, 267, 270, 275, 277, 279, 282, 283, 284, 285, 286, 288, 290, 291, 293, 295, 297, 299, 312, 315, 316, 318, 322, 324, 330, 331, 336, 341, 345, 346, 356, 358, 360, 361, 362, 364, 373, 381, 383, 390, 391, 392, 393, 394, 395, 398, 403, 404, 407, 409, 413, 430, 434, 435, 440, 442, 443, 444, 446, 457, 467, 470, 471, 474, 478, 484, 485, 486, 487, 489, 490, 491, 493, 494, 495, 496, 497, 498, 499, 504, 506, 508, 509, 510, 513, 517, 518, 519, 522, 524, 527, 528, 531, 537, 539, 543, 547, 548, 549, 550, 551, 552, 553, 557, 558, 559, 563, 565, 567, 570, 571, 572, 574, 576, 579, 580, 581, 582, 588, 592, 594, 595, 596, 598, 599, 601, 604, 606, 607, 609, 612, 613, 615, 621, 624, 625, 629, 630, 632, 635, 642, 644, 645, 647, 649, 653, 655, 660, 662, 665, 666, 667, 669, 672, 679, 681, 682, 683, 686, 687, 689, 692, 693, 694, 695, 698, 699, 702, 706, 708, 722, 725, 731, 734, 736, 737, 739, 746, 747, 749, 755, 756, 760, 762, 765, 768, 775, 777, 778, 780, 782, 783, 786, 787, 790, 791, 793, 796, 798, 803, 804, 808, 812, 813, 815, 819, 821, 824, 826, 827, 828, 829, 836, 837, 839, 841, 842, 844, 845, 846, 848, 849, 850, 852, 854, 855, 856, 857, 859, 860, 861, 863, 864, 865, 866, 873, 876, 884, 887, 888, 891, 892, 894, 896, 897, 898\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom EEG reference.\n",
      "Fitted sphere radius:         95.1 mm\n",
      "Origin head coordinates:      0.9 6.5 47.0 mm\n",
      "Origin device coordinates:    0.9 6.5 47.0 mm\n",
      "Reading /net/store/nbp/projects/hyperscanning/study_project/dirk/NBP_Hyperscanning/data_analysis/bads/bad_components/sub-202_p-1-ica.fif ...\n",
      "Now restoring ICA solution ...\n",
      "Ready.\n",
      "Transforming to ICA space (63 components)\n",
      "Zeroing out 2 ICA components\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "548c9d7d9aae4d229f2b1373ac4b15ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Repairing epochs', layout=Layout(flex='2'), max=900.0, st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dropped 8 epochs: 44, 53, 90, 146, 157, 164, 211, 293\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom EEG reference.\n",
      "Fitted sphere radius:         95.1 mm\n",
      "Origin head coordinates:      0.9 6.5 47.0 mm\n",
      "Origin device coordinates:    0.9 6.5 47.0 mm\n"
     ]
    }
   ],
   "source": [
    "# split the epochs to apply AR & ICA individually\n",
    "epochs_split = list(split_epochs(epochs))\n",
    "for i, cur_eps in enumerate(epochs_split):\n",
    "    subj_id = \"sub-{0}_p-{1}\".format(subj_pair, i)\n",
    "    \n",
    "    # apply ICA\n",
    "    ica = load_ica(subj_id)\n",
    "    cur_eps = ica.apply(cur_eps)\n",
    "\n",
    "    # apply autoreject (exclude bads and interpolate)\n",
    "    # TODO: The Autoreject guys apply ICA first and then autoreject local. i would do the same\n",
    "    ar = load_autoreject(subj_id)\n",
    "    cur_eps = ar.transform(cur_eps, return_log=False)\n",
    "\n",
    "\n",
    "\n",
    "    # rereference to avg ref\n",
    "    cur_eps.set_eeg_reference(ref_channels='average')\n",
    "\n",
    "    # APPLY LAPLACIAN\n",
    "    cur_eps = mne.preprocessing.compute_current_source_density(cur_eps,\n",
    "                                                               stiffness=10,\n",
    "                                                               lambda2=1e-5)\n",
    "    epochs_split[i] = cur_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AutoReject' object has no attribute 'reject_log'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-6a79bacc5463>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreject_log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#np.array(epochs_split[0].drop_log)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AutoReject' object has no attribute 'reject_log'"
     ]
    }
   ],
   "source": [
    "a = [True if i ==[] else False for i in epochs_split[0].drop_log]\n",
    "b = [True if i ==[] else False for i in epochs_split[1].drop_log]\n",
    "\n",
    "drop_mask = np.logical_and(a, b)\n",
    "drop_log = [a + b for a, b in zip(epochs_split[0].drop_log, epochs_split[1].drop_log)]\n",
    "np.sum(drop_mask)\n",
    "\n",
    "\n",
    "\n",
    "#np.array(epochs_split[0].drop_log)\n",
    "#[i for i in epochs_split[0].drop_log if ]\n",
    "#epochs_split[i].drop_log != []\n",
    "#np.logical_and(, epochs_split[0].drop_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of bad_epochs\n",
    "combined_epochs = np.logical_or(ars[0].get_reject_log(epochs).bad_epochs, ars[1].get_reject_log(epochs).bad_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(combined_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
