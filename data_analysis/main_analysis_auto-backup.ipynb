{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Analysis\n",
    "\n",
    "This file does not rely on user input. So we would like to keep it interchangeable with the actual main_analysis.py file.\n",
    "So please keep all the >relevant< code within one code block. (If you want to inspect certain elements or do other things that are not relevant to the main analysis, you can of course add them in new blocks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/net/store/nbp/projects/hyperscanning/study_project/programming_tools/miniconda3/envs/hyperscanning/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /net/store/nbp/projects/hyperscanning/hyperscanning-2.0/mne_data/sourcedata/sub-204/eeg/sub-204_task-hyper_eeg.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-5898b7c3cc28>:41: RuntimeWarning: This filename (/net/store/nbp/projects/hyperscanning/hyperscanning-2.0/mne_data/sourcedata/sub-204/eeg/sub-204_task-hyper_eeg.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz or _meg.fif\n",
      "  combined_raw = mne.io.read_raw_fif(subs_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isotrak not found\n",
      "    Range : 0 ... 3537048 =      0.000 ...  3454.148 secs\n",
      "Ready.\n",
      "Reading 0 ... 3537048  =      0.000 ...  3454.148 secs...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying a custom EEG reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying a custom EEG reference.\n",
      "6638 events found\n",
      "Event IDs: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 36 37 38 39 40 41 42 43 44 45 46 48 49]\n",
      "6638 events found\n",
      "Event IDs: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 36 37 38 39 40 41 42 43 44 45 46 48 49]\n",
      "900 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 900 events and 1537 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-5898b7c3cc28>:83: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw_combined, combined_events, tmin=tmin, tmax=tmax,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Dropped 891 epochs: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b2c713aac44032adaaa9a078b74780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Repairing epochs', layout=Layout(flex='2'), max=9.0, styl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No bad epochs were found for your data. Returning a copy of the data you wanted to clean. Interpolation may have been done.\n",
      "Reading /net/store/nbp/projects/hyperscanning/study_project/dirk/NBP_Hyperscanning/data_analysis/bads/bad_components/sub-204_p-0-ica.fif ...\n",
      "Now restoring ICA solution ...\n",
      "Ready.\n",
      "Transforming to ICA space (63 components)\n",
      "Zeroing out 2 ICA components\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom EEG reference.\n",
      "Fitted sphere radius:         95.1 mm\n",
      "Origin head coordinates:      0.9 6.5 47.0 mm\n",
      "Origin device coordinates:    0.9 6.5 47.0 mm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79011d737625409bbfc53f3ee7482459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Repairing epochs', layout=Layout(flex='2'), max=9.0, styl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No bad epochs were found for your data. Returning a copy of the data you wanted to clean. Interpolation may have been done.\n",
      "Reading /net/store/nbp/projects/hyperscanning/study_project/dirk/NBP_Hyperscanning/data_analysis/bads/bad_components/sub-204_p-1-ica.fif ...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/net/store/nbp/projects/hyperscanning/study_project/dirk/NBP_Hyperscanning/data_analysis/bads/bad_components/sub-204_p-1-ica.fif'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5898b7c3cc28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# apply ICA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mica\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_ica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubj_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mcur_eps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mica\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_eps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/store/nbp/projects/hyperscanning/study_project/dirk/NBP_Hyperscanning/data_analysis/functions_preprocessing.py\u001b[0m in \u001b[0;36mload_ica\u001b[0;34m(subj_id)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;34m\"\"\"Load an ICA object to the predefined folder.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0mica_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBAD_COMP_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubj_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"-ica.fif\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_ica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mica_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-358>\u001b[0m in \u001b[0;36mread_ica\u001b[0;34m(fname, verbose)\u001b[0m\n",
      "\u001b[0;32m/net/store/nbp/projects/hyperscanning/study_project/programming_tools/miniconda3/envs/hyperscanning/lib/python3.8/site-packages/mne/preprocessing/ica.py\u001b[0m in \u001b[0;36mread_ica\u001b[0;34m(fname, verbose)\u001b[0m\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reading %s ...'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2105\u001b[0;31m     \u001b[0mfid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiff_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2107\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-6>\u001b[0m in \u001b[0;36mfiff_open\u001b[0;34m(fname, preload, verbose)\u001b[0m\n",
      "\u001b[0;32m/net/store/nbp/projects/hyperscanning/study_project/programming_tools/miniconda3/envs/hyperscanning/lib/python3.8/site-packages/mne/io/open.py\u001b[0m in \u001b[0;36mfiff_open\u001b[0;34m(fname, preload, verbose)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \"\"\"\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fiff_get_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0;31m# do preloading of entire file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/store/nbp/projects/hyperscanning/study_project/programming_tools/miniconda3/envs/hyperscanning/lib/python3.8/site-packages/mne/io/open.py\u001b[0m in \u001b[0;36m_fiff_get_fid\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using normal I/O'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Open in binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/net/store/nbp/projects/hyperscanning/study_project/dirk/NBP_Hyperscanning/data_analysis/bads/bad_components/sub-204_p-1-ica.fif'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os.path as op\n",
    "module_path = op.abspath(op.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "from hypyp.prep import AR_local\n",
    "\n",
    "from data_analysis.functions_preprocessing import \\\n",
    "    (combine_raws, split_raws, combine_epochs, split_epochs,\n",
    "     preprocess_single_sub, load_ica, load_autoreject)\n",
    "from data_analysis.functions_behavioral import \\\n",
    "    (create_event_df, remove_ghost_triggers, calculate_alpha,\n",
    "     join_event_dfs, remove_outliers, events_from_event_df)\n",
    "from data_analysis.functions_connectivity import \\\n",
    "    epochs_ispc\n",
    "from data_analysis.functions_graph_theory import \\\n",
    "    epochs_weighted_small_world_coeff\n",
    "\n",
    "\n",
    "\n",
    "subject_dir = \"/net/store/nbp/projects/hyperscanning/hyperscanning-2.0/mne_data/sourcedata/\"\n",
    "behav_dir = \"/net/store/nbp/projects/hyperscanning/study_project/NBP_Hyperscanning/data_analysis/Behavioural_Analysis/BehaviouralData\"\n",
    "\n",
    "\n",
    "\n",
    "# Main Data Analysis ###################################\n",
    "# initialize containers to analyze later\n",
    "connectivity_matrices = []\n",
    "small_world_coeffs = []\n",
    "\n",
    "# Perform the data analysis\n",
    "for subj_pair in ['204']:  #['202','203','204','205','206','207','208','209','211','212']:\n",
    "\n",
    "    subs_path = subject_dir + \"sub-{0}/eeg/sub-{0}_task-hyper_eeg.fif\".format(subj_pair)\n",
    "    behav_path = op.join(behav_dir, \"{0}.csv\".format(subj_pair))\n",
    "\n",
    "    combined_raw = mne.io.read_raw_fif(subs_path, preload=True)\n",
    "\n",
    "    # split the subjects and delete the raw file\n",
    "    raws = split_raws(combined_raw)\n",
    "    del combined_raw\n",
    "    \n",
    "    for i, _ in enumerate(raws):\n",
    "        # set the EEG Montage. We use 64 chans from the standard 10-05 system.\n",
    "        montage = mne.channels.make_standard_montage(\"standard_1005\")\n",
    "        raws[i].set_montage(montage)\n",
    "\n",
    "    # combine the subjects again\n",
    "    raw_combined = combine_raws(raws[0], raws[1])\n",
    "    del raws  # to save memory\n",
    "\n",
    "    # do the behavioral analysis and get the epochs\n",
    "    behavioral_df = calculate_alpha(pd.read_csv(behav_path))\n",
    "    event_df = create_event_df(raw_combined)\n",
    "    event_df = remove_ghost_triggers(event_df)\n",
    "    event_df = join_event_dfs(event_df, behavioral_df)\n",
    "    \n",
    "    # get the first tap by looking at the first sample in each trial\n",
    "    min_idx = event_df.groupby([\"trial\"])[\"sample\"].idxmin()\n",
    "    early_df = event_df[event_df.index.isin(min_idx)]\n",
    "    early_events = events_from_event_df(early_df)\n",
    "    \n",
    "    # get the late taps by looking at the last sample - 1.5 seconds\n",
    "    max_idx = event_df.groupby([\"trial\"])[\"sample\"].idxmax()\n",
    "    late_df = event_df[event_df.index.isin(max_idx)]\n",
    "    late_events = events_from_event_df(late_df)\n",
    "    late_events[:,0] -= int(raw_combined.info[\"sfreq\"] * 1.5)\n",
    "    \n",
    "    # get the baseline events\n",
    "    base_events = mne.pick_events(mne.find_events(raw_combined, shortest_event=1),\n",
    "                              include=48)\n",
    "\n",
    "    # define the parameters for epoching\n",
    "    combined_events = np.vstack([base_events, early_events, late_events])\n",
    "    tmin = 0\n",
    "    tmax = 1.5\n",
    "\n",
    "    # epoch the data. Here we filter out bad segments from both participants\n",
    "    epochs = mne.Epochs(raw_combined, combined_events, tmin=tmin, tmax=tmax,\n",
    "                        picks=[\"eeg\"], baseline=None, preload=True) # only use the first two epochs\n",
    "    \n",
    "    # we have to combine both autoreject thresholds first and remove the manually\n",
    "    rejects = [load_autoreject(\"sub-{0}_p-{1}\".format(subj_pair, i)).get_reject_log(split_epochs(epochs)[i]).bad_epochs for i in range(2)]\n",
    "    combined_rejects = np.logical_or(rejects[0], rejects[1])\n",
    "    \n",
    "    \n",
    "    # apply the heuristic to reject all parts of a trial if 2 or more epochs out of\n",
    "    # baseline, early, and late, are bad.\n",
    "    bad_trials = np.vstack([combined_rejects[:300],\n",
    "                            combined_rejects[300:600],\n",
    "                            combined_rejects[600:]])\n",
    "    bad_trial_sets = np.sum(bad_trials, axis=0) >= 1\n",
    "    combined_rejects = np.hstack([bad_trial_sets] * 3)\n",
    "    \n",
    "    epochs = epochs.drop(combined_rejects, reason=\"Autoreject\")\n",
    "    \n",
    "     # split the epochs to apply ICA individually\n",
    "    epochs_split = list(split_epochs(epochs))\n",
    "    for i, cur_eps in enumerate(epochs_split):\n",
    "        subj_id = \"sub-{0}_p-{1}\".format(subj_pair, i)\n",
    "\n",
    "        # apply autoreject (exclude bads and interpolate)\n",
    "        # TODO: The Autoreject guys apply ICA first and then autoreject local. i would do the same\n",
    "        # Applying ICA first will look ugly, but for the first pair, it saves ~ 50 epochs\n",
    "        ar = load_autoreject(subj_id)\n",
    "        cur_eps = ar.transform(cur_eps, return_log=False)\n",
    "\n",
    "        # apply ICA\n",
    "        ica = load_ica(subj_id)\n",
    "        cur_eps = ica.apply(cur_eps)\n",
    "        \n",
    "        # rereference to avg ref\n",
    "        cur_eps.set_eeg_reference(ref_channels='average')\n",
    "\n",
    "        # apply surface laplacian\n",
    "        cur_eps = mne.preprocessing.compute_current_source_density(cur_eps,\n",
    "                                                                   stiffness=10,\n",
    "                                                                   lambda2=1e-5)\n",
    "        epochs_split[i] = cur_eps\n",
    "\n",
    "    #combine the epochs again\n",
    "    epochs = combine_epochs(epochs_split[0], epochs_split[1])\n",
    "    del epochs_split\n",
    "    \n",
    "    # frequencies should be 25 freqs, log spaced between 4 and 50\n",
    "    freqs = np.logspace(np.log10(4), np.log10(45), 20)\n",
    "    cycles = freqs / 2.\n",
    "    \n",
    "    raise ValueError(\"YOU SHALL NOT PASS!\")\n",
    "    print(\"STARTING WITH ISPC\")\n",
    "    \n",
    "    # calculate the ISPC\n",
    "    ispc_matrix, freqs, times = epochs_ispc(epochs, freqs, cycles, n_jobs=4)\n",
    "    \n",
    "    print(\"ISPC DONE\")\n",
    "    \n",
    "    # calculate the small world coefficient\n",
    "    small_worlds = epochs_weighted_small_world_coeff(ispc_matrix)\n",
    "    \n",
    "    # append the results to the respective lists\n",
    "    connectivity_matrices.append(ispc_matrix)\n",
    "    small_world_coeffs.append(small_worlds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(epochs)/3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # apply the heuristic to reject all parts of a trial if 2 or more epochs out of\n",
    "    # baseline, early, and late, are bad.\n",
    "    bad_trials = np.vstack([combined_rejects[:300],\n",
    "                            combined_rejects[300:600],\n",
    "                            combined_rejects[600:]])\n",
    "    bad_trial_sets = np.sum(bad_trials, axis=0) >= 2\n",
    "    combined_rejects = np.hstack([bad_trial_sets] * 3)\n",
    "    \n",
    "    epochs = epochs.drop(combined_rejects, reason=\"Autoreject\")\n",
    "    \n",
    "     # split the epochs to apply ICA individually\n",
    "    epochs_split = list(split_epochs(epochs))\n",
    "    for i, cur_eps in enumerate(epochs_split):\n",
    "        subj_id = \"sub-{0}_p-{1}\".format(subj_pair, i)\n",
    "\n",
    "        # apply autoreject (exclude bads and interpolate)\n",
    "        # TODO: The Autoreject guys apply ICA first and then autoreject local. i would do the same\n",
    "        # Applying ICA first will look ugly, but for the first pair, it saves ~ 50 epochs\n",
    "        #ar = load_autoreject(subj_id)\n",
    "        #cur_eps = ar.transform(cur_eps, return_log=False)\n",
    "\n",
    "        # apply ICA\n",
    "        ica = load_ica(subj_id)\n",
    "        epochs_split[i] = ica.apply(cur_eps)\n",
    "        \n",
    "    # for AR_local from hypyp, we have to work on the list again\n",
    "    epochs_split, AR_dict = AR_local(epochs_split)  # would be nice to test out parameter strategy=\"intersection\"\n",
    "    \n",
    "    for i, cur_eps in enumerate(epochs_split):\n",
    "        \n",
    "        # rereference to avg ref\n",
    "        cur_eps.set_eeg_reference(ref_channels='average')\n",
    "\n",
    "        # apply surface laplacian\n",
    "        cur_eps = mne.preprocessing.compute_current_source_density(cur_eps,\n",
    "                                                                   stiffness=10,\n",
    "                                                                   lambda2=1e-5)\n",
    "        epochs_split[i] = cur_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 435 epochs: 0, 1, 2, 3, 4, 5, 8, 9, 10, 12, 16, 17, 22, 23, 24, 28, 30, 31, 35, 36, 39, 40, 41, 44, 47, 48, 49, 50, 52, 53, 55, 59, 60, 61, 64, 65, 66, 67, 68, 70, 71, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 99, 100, 102, 107, 114, 116, 120, 121, 123, 126, 132, 133, 135, 138, 140, 144, 145, 146, 147, 152, 155, 157, 158, 160, 164, 166, 167, 168, 170, 173, 174, 175, 176, 178, 179, 180, 181, 182, 184, 185, 186, 188, 190, 191, 192, 193, 195, 197, 199, 203, 206, 208, 210, 211, 212, 213, 215, 217, 218, 219, 220, 222, 223, 224, 225, 226, 227, 229, 231, 232, 235, 237, 238, 239, 240, 242, 246, 250, 251, 252, 254, 255, 256, 257, 258, 259, 260, 265, 267, 270, 273, 274, 275, 276, 277, 279, 282, 283, 284, 285, 286, 288, 290, 291, 293, 295, 297, 299, 312, 313, 316, 318, 320, 322, 324, 325, 330, 331, 336, 338, 341, 345, 347, 354, 356, 358, 360, 361, 362, 364, 373, 381, 383, 386, 389, 390, 391, 392, 393, 394, 395, 398, 403, 404, 407, 409, 413, 425, 430, 434, 435, 440, 442, 443, 444, 446, 457, 461, 464, 467, 470, 471, 474, 478, 485, 486, 487, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 504, 506, 508, 509, 510, 513, 517, 518, 519, 522, 524, 527, 528, 530, 531, 537, 539, 543, 547, 548, 549, 550, 551, 552, 553, 554, 557, 558, 559, 563, 565, 567, 570, 571, 572, 573, 576, 579, 581, 582, 588, 590, 592, 594, 595, 596, 598, 599, 601, 603, 604, 605, 606, 607, 609, 612, 613, 615, 620, 621, 624, 625, 629, 630, 632, 635, 637, 642, 644, 645, 647, 648, 649, 652, 653, 655, 659, 660, 662, 665, 666, 667, 669, 672, 673, 681, 682, 683, 686, 687, 688, 689, 692, 693, 694, 695, 696, 698, 699, 702, 703, 706, 708, 718, 722, 725, 731, 732, 734, 736, 737, 738, 739, 742, 744, 746, 747, 749, 755, 756, 760, 761, 762, 765, 767, 768, 774, 775, 777, 778, 780, 782, 783, 785, 786, 787, 788, 790, 791, 793, 796, 798, 802, 803, 804, 805, 806, 808, 812, 813, 815, 816, 817, 819, 821, 824, 826, 827, 828, 829, 830, 836, 837, 839, 840, 841, 842, 844, 845, 846, 848, 849, 850, 852, 854, 855, 856, 857, 859, 860, 861, 863, 864, 865, 866, 873, 876, 883, 884, 887, 888, 891, 892, 894, 896, 897, 898, 899\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf7afa08f974879a0c359dd196f75c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Repairing epochs', layout=Layout(flex='2'), max=465.0, st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No bad epochs were found for your data. Returning a copy of the data you wanted to clean. Interpolation may have been done.\n",
      "Reading /net/store/nbp/projects/hyperscanning/study_project/dirk/NBP_Hyperscanning/data_analysis/bads/bad_components/sub-202_p-0-ica.fif ...\n",
      "Now restoring ICA solution ...\n",
      "Ready.\n",
      "Transforming to ICA space (63 components)\n",
      "Zeroing out 1 ICA component\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom EEG reference.\n",
      "Fitted sphere radius:         95.1 mm\n",
      "Origin head coordinates:      0.9 6.5 47.0 mm\n",
      "Origin device coordinates:    0.9 6.5 47.0 mm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae62671066e4d07897982d38bd589e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Repairing epochs', layout=Layout(flex='2'), max=465.0, st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No bad epochs were found for your data. Returning a copy of the data you wanted to clean. Interpolation may have been done.\n",
      "Reading /net/store/nbp/projects/hyperscanning/study_project/dirk/NBP_Hyperscanning/data_analysis/bads/bad_components/sub-202_p-1-ica.fif ...\n",
      "Now restoring ICA solution ...\n",
      "Ready.\n",
      "Transforming to ICA space (63 components)\n",
      "Zeroing out 2 ICA components\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom EEG reference.\n",
      "Fitted sphere radius:         95.1 mm\n",
      "Origin head coordinates:      0.9 6.5 47.0 mm\n",
      "Origin device coordinates:    0.9 6.5 47.0 mm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    epochs_split = list(split_epochs(epochs))\n",
    "    for i, cur_eps in enumerate(epochs_split):\n",
    "        subj_id = \"sub-{0}_p-{1}\".format(subj_pair, i)\n",
    "\n",
    "        # apply autoreject (exclude bads and interpolate)\n",
    "        # TODO: The Autoreject guys apply ICA first and then autoreject local. i would do the same\n",
    "        ar = load_autoreject(subj_id)\n",
    "        cur_eps = ar.transform(cur_eps, return_log=False)\n",
    "\n",
    "        # apply ICA\n",
    "        ica = load_ica(subj_id)\n",
    "        cur_eps = ica.apply(cur_eps)\n",
    "        \n",
    "        # rereference to avg ref\n",
    "        cur_eps.set_eeg_reference(ref_channels='average')\n",
    "\n",
    "        # APPLY LAPLACIAN\n",
    "        cur_eps = mne.preprocessing.compute_current_source_density(cur_eps,\n",
    "                                                                   stiffness=10,\n",
    "                                                                   lambda2=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "file \"/net/store/nbp/projects/hyperscanning/study_project/dirk/NBP_Hyperscanning/data_analysis/bads/bad_autoreject/sub-204_p-1-ar.hdf5\" not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4bd210151749>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# we have to combine both autoreject thresholds first and remove the manually\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrejects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mload_autoreject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sub-{0}_p-{1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubj_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_reject_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbad_epochs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcombined_rejects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrejects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrejects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_rejects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Autoreject\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-4bd210151749>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# we have to combine both autoreject thresholds first and remove the manually\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrejects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mload_autoreject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sub-{0}_p-{1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubj_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_reject_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbad_epochs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcombined_rejects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrejects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrejects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_rejects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Autoreject\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/store/nbp/projects/hyperscanning/study_project/dirk/NBP_Hyperscanning/data_analysis/functions_preprocessing.py\u001b[0m in \u001b[0;36mload_autoreject\u001b[0;34m(subj_id)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mautoreject\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_auto_reject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0mar_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBAD_AR_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubj_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"-ar.hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mread_auto_reject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/store/nbp/projects/hyperscanning/study_project/programming_tools/miniconda3/envs/hyperscanning/lib/python3.8/site-packages/autoreject/autoreject.py\u001b[0m in \u001b[0;36mread_auto_reject\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mautoreject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoReject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \"\"\"\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'autoreject'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0minit_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INIT_PARAMS\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'verbose'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/store/nbp/projects/hyperscanning/study_project/programming_tools/miniconda3/envs/hyperscanning/lib/python3.8/site-packages/mne/externals/h5io/_h5io.py\u001b[0m in \u001b[0;36mread_hdf5\u001b[0;34m(fname, title, slash)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0mh5py\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_h5py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'file \"%s\" not found'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'title must be a string'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: file \"/net/store/nbp/projects/hyperscanning/study_project/dirk/NBP_Hyperscanning/data_analysis/bads/bad_autoreject/sub-204_p-1-ar.hdf5\" not found"
     ]
    }
   ],
   "source": [
    "    # we have to combine both autoreject thresholds first and remove the manually\n",
    "    rejects = [load_autoreject(\"sub-{0}_p-{1}\".format(subj_pair, i)).get_reject_log(split_epochs(epochs)[i]).bad_epochs for i in range(2)]\n",
    "    combined_rejects = np.logical_or(rejects[0], rejects[1])\n",
    "    epochs = epochs.drop(combined_rejects, reason=\"Autoreject\")[::30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 64 is out of bounds for axis 0 with size 64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-2b0cc481c55d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mepochs_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/net/store/nbp/projects/hyperscanning/study_project/dirk/NBP_Hyperscanning/data_analysis/functions_preprocessing.py\u001b[0m in \u001b[0;36msplit_epochs\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m    106\u001b[0m     epochs_1 = epochs.copy().pick_channels([ch for ch in epochs.ch_names if ch[:4] == \"sub1\"],\n\u001b[1;32m    107\u001b[0m                                            ordered=True)\n\u001b[0;32m--> 108\u001b[0;31m     epochs_2 = epochs.copy().pick_channels([ch for ch in epochs.ch_names if ch[:4] == \"sub2\"],\n\u001b[0m\u001b[1;32m    109\u001b[0m                                            ordered=True)\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/store/nbp/projects/hyperscanning/study_project/programming_tools/miniconda3/envs/hyperscanning/lib/python3.8/site-packages/mne/channels/channels.py\u001b[0m in \u001b[0;36mpick_channels\u001b[0;34m(self, ch_names, ordered)\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mversionadded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;36m.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \"\"\"\n\u001b[0;32m--> 743\u001b[0;31m         return self._pick_drop_channels(\n\u001b[0m\u001b[1;32m    744\u001b[0m             pick_channels(self.info['ch_names'], ch_names, ordered=ordered))\n\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/store/nbp/projects/hyperscanning/study_project/programming_tools/miniconda3/envs/hyperscanning/lib/python3.8/site-packages/mne/channels/channels.py\u001b[0m in \u001b[0;36m_pick_drop_channels\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'picks'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpicks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpicks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cals'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 64 is out of bounds for axis 0 with size 64"
     ]
    }
   ],
   "source": [
    "    epochs_split = list(split_epochs(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [True if i ==[] else False for i in epochs_split[0].drop_log]\n",
    "b = [True if i ==[] else False for i in epochs_split[1].drop_log]\n",
    "\n",
    "drop_mask = np.logical_and(a, b)\n",
    "drop_log = [a + b for a, b in zip(epochs_split[0].drop_log, epochs_split[1].drop_log)]\n",
    "np.sum(drop_mask)\n",
    "\n",
    "\n",
    "\n",
    "#np.array(epochs_split[0].drop_log)\n",
    "#[i for i in epochs_split[0].drop_log if ]\n",
    "#epochs_split[i].drop_log != []\n",
    "#np.logical_and(, epochs_split[0].drop_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of bad_epochs\n",
    "combined_epochs = np.logical_or(ars[0].get_reject_log(epochs).bad_epochs, ars[1].get_reject_log(epochs).bad_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(combined_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
