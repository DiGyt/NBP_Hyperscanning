{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Analysis\n",
    "\n",
    "This file does not rely on user input. So we would like to keep it interchangeable with the actual main_analysis.py file.\n",
    "So please keep all the >relevant< code within one code block. (If you want to inspect certain elements or do other things that are not relevant to the main analysis, you can of course add them in new blocks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /net/store/nbp/projects/hyperscanning/hyperscanning-2.0/mne_data/sourcedata/sub-204/eeg/sub-204_task-hyper_eeg.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-ad92dac54aea>:40: RuntimeWarning: This filename (/net/store/nbp/projects/hyperscanning/hyperscanning-2.0/mne_data/sourcedata/sub-204/eeg/sub-204_task-hyper_eeg.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz or _meg.fif\n",
      "  combined_raw = mne.io.read_raw_fif(subs_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isotrak not found\n",
      "    Range : 0 ... 3537048 =      0.000 ...  3454.148 secs\n",
      "Ready.\n",
      "Reading 0 ... 3537048  =      0.000 ...  3454.148 secs...\n",
      "6638 events found\n",
      "Event IDs: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 36 37 38 39 40 41 42 43 44 45 46 48 49]\n",
      "267 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 10 events and 1025 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  14 tasks      | elapsed:    3.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 112 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=4)]: Done 128 out of 128 | elapsed:    4.3s finished\n",
      "/net/store/nbp/projects/hyperscanning/study_project/dirk/NBP_Hyperscanning/data_analysis/functions_connectivity.py:44: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  ispc_matrix[epoch, chan_a, chan_b, freq] = core_ispc(phase_diff[freq], times)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os.path as op\n",
    "module_path = op.abspath(op.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "\n",
    "from data_analysis.functions_preprocessing import \\\n",
    "    (combine_raws, split_raws, preprocess_single_sub, mark_bads_and_save,\n",
    "     run_ica_and_save)\n",
    "from data_analysis.functions_behavioral import \\\n",
    "    (create_event_df, remove_ghost_triggers, calculate_alpha,\n",
    "     join_event_dfs, remove_outliers, events_from_event_df)\n",
    "from data_analysis.functions_connectivity import \\\n",
    "    epochs_ispc\n",
    "from data_analysis.functions_graph_theory import \\\n",
    "    epochs_weighted_small_world_coeff\n",
    "\n",
    "\n",
    "\n",
    "subject_dir = \"/net/store/nbp/projects/hyperscanning/hyperscanning-2.0/mne_data/sourcedata/\"\n",
    "behav_dir = \"/net/store/nbp/projects/hyperscanning/study_project/NBP_Hyperscanning/data_analysis/Behavioural_Analysis/BehaviouralData\"\n",
    "\n",
    "\n",
    "\n",
    "# Main Data Analysis ###################################\n",
    "# initialize containers to analyze later\n",
    "connectivity_matrices = []\n",
    "small_world_coeffs = []\n",
    "\n",
    "# Perform the data analysis\n",
    "for subj_pair in ['204']:  #['202','203','204','205','206','207','208','209','211','212']:\n",
    "\n",
    "    subs_path = subject_dir + \"sub-{0}/eeg/sub-{0}_task-hyper_eeg.fif\".format(subj_pair)\n",
    "    behav_path = op.join(behav_dir, \"{0}.csv\".format(subj_pair))\n",
    "\n",
    "    combined_raw = mne.io.read_raw_fif(subs_path, preload=True)\n",
    "\n",
    "    # split the subjects and delete the raw file\n",
    "    raws = split_raws(combined_raw)\n",
    "    del combined_raw\n",
    "\n",
    "    # apply the preprocessing\n",
    "    #for idx, raw in enumerate(raws):\n",
    "    #    subj_idx = \"sub-{0}_p-{1}\".format(subj_pair, idx)\n",
    "    #    raws[idx] = preprocess_single_sub(raw, subj_idx)\n",
    "\n",
    "\n",
    "    # combine the subjects again\n",
    "    raw_combined = combine_raws(raws[0], raws[1])\n",
    "    del raws  # to save memory\n",
    "\n",
    "    # do the behavioral analysis and get the epochs\n",
    "    behavioral_df = calculate_alpha(pd.read_csv(behav_path))\n",
    "    \n",
    "    event_df = create_event_df(raw_combined)\n",
    "    event_df = remove_ghost_triggers(event_df)\n",
    "    event_df = join_event_dfs(event_df, behavioral_df)\n",
    "    event_df = remove_outliers(event_df, exclude_stddev=2)\n",
    "    events = events_from_event_df(event_df)\n",
    "\n",
    "    # define the parameters for epoching\n",
    "    # TODO: Define events more elaborate!\n",
    "    event_id = 11\n",
    "    tmin = 0\n",
    "    tmax = 1\n",
    "\n",
    "    # epoch the data. Here we filter out bad segments from both participants\n",
    "    # TODO: do we need a baseline for the connectivity analysis?\n",
    "    epochs = mne.Epochs(raw_combined, events, event_id, tmin, tmax,\n",
    "                        picks=[\"eeg\"], baseline=(0, 0),\n",
    "                        reject_by_annotation=True)[:10] # only use the first ten epochs\n",
    "    \n",
    "    # calculate the ISPC\n",
    "    freqs = np.arange(5,15,5)\n",
    "    cycles = freqs / 2.\n",
    "    ispc_matrix, freqs, times = epochs_ispc(epochs, freqs, cycles, n_jobs=4)\n",
    "    \n",
    "    print(\"ISPC DONE\")\n",
    "    \n",
    "    # calculate the small world coefficient\n",
    "    small_worlds = epochs_weighted_small_world_coeff(ispc_matrix)\n",
    "    \n",
    "    # append the results to the respective lists\n",
    "    connectivity_matrices.append(ispc_matrix)\n",
    "    small_world_coeffs.append(small_worlds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: There seems to be a bug in the data from the very beginning.\n",
    "# The channels are somehow already referenced, even though we don't have a ref.\n",
    "# and the one thats supposed to be mapped to Cz (for subject 2) is not the one thats referenced.\n",
    "# Instead, the Oz electrode was used for the reference. Looks like we have to dig in the script from Max.\n",
    "# Or change the mapping order.\n",
    "print(raw_combined.get_data(picks=[\"sub1_Cz\", \"sub2_Oz\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate stuff\n",
    "\n",
    "Here, you can look into all the stuff, connectivity matrices etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#event_df[event_df[\"alpha\"] > 360]\n",
    "event_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the ISPC matrix\n",
    "from functions_connectivity import plot_connectivity_matrix\n",
    "\n",
    "print(\"Freqs: \", freqs)\n",
    "\n",
    "plot_connectivity_matrix(np.squeeze(ispc_matrix[0, :,:,0]), epochs.ch_names, title=\"ISPC for freq = \"+ str(freqs[0]))\n",
    "\n",
    "plot_connectivity_matrix(np.squeeze(ispc_matrix[0, :,:,1]), epochs.ch_names, title=\"ISPC for freq = \"+ str(freqs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the average ISPC matrix\n",
    "avg_ispc = np.mean(ispc_matrix, axis=0)\n",
    "\n",
    "plot_connectivity_matrix(np.squeeze(avg_ispc[:,:,0]), epochs.ch_names, title=\"ISPC for freq = \"+ str(freqs[0]))\n",
    "plot_connectivity_matrix(np.squeeze(avg_ispc[:,:,1]), epochs.ch_names, title=\"ISPC for freq = \"+ str(freqs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a connectivity circle\n",
    "from mne.viz import plot_connectivity_circle\n",
    "\n",
    "mne.viz.plot_connectivity_circle(ispc_matrix[0, :,:,1], epochs.ch_names, vmin=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a connectivity circle for the average matrix\n",
    "\n",
    "mne.viz.plot_connectivity_circle(avg_ispc[:,:,1], epochs.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(np.array(epochs.ch_names) == \"sub1_Cz\"),\n",
    "      np.where(np.array(epochs.ch_names) == \"sub2_Oz\"))\n",
    "\n",
    "ispc_matrix[:, 15, 94, 1]\n",
    "epochs.get_data()[:,15,:]\n",
    "epochs.get_data()[:,94,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
